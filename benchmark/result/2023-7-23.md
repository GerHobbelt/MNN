### i7-13700KF + RTX 4070 Ti

#### MNN(CPU)
(base) PS C:\Code\mnn\MNN\build> .\benchmark.out.exe ..\modelzoo\mnn 1000 10 0
MNN benchmark
Forward type: **CPU** thread=4** precision=2** sparsity=0** sparseBlockOC=1** testQuantizedModel=0
--------> Benchmarking... loop = 1000, warmup = 10
Float model test...
The device support i8sdot:0, support fp16:0, support i8mm: 0
[ - ] resnet18.mnn                max =   22.673 ms  min =    7.945 ms  avg =    8.455 ms

#### MNN(CUDA)
(base) PS C:\Code\mnn\MNN\build> .\benchmark.out.exe ..\modelzoo\mnn 1000 10 2
MNN benchmark
Forward type: **CUDA** thread=4** precision=2** sparsity=0** sparseBlockOC=1** testQuantizedModel=0
--------> Benchmarking... loop = 1000, warmup = 10
Float model test...
The device support i8sdot:0, support fp16:0, support i8mm: 0
[ - ] resnet18.mnn                max =    0.875 ms  min =    0.356 ms  avg =    0.377 ms

#### TensorRT(trtexec)
C:\Code\mnn\MNN>trtexec --onnx=modelzoo/onnx/resnet18.onnx --iterations=1000
&&&& RUNNING TensorRT.trtexec [TensorRT v8601] # trtexec --onnx=modelzoo/onnx/resnet18.onnx --iterations=1000
[07/23/2023-17:20:54] [I] === Model Options ===
[07/23/2023-17:20:54] [I] Format: ONNX
[07/23/2023-17:20:54] [I] Model: modelzoo/onnx/resnet18.onnx
[07/23/2023-17:20:54] [I] Output:
[07/23/2023-17:20:54] [I] === Build Options ===
[07/23/2023-17:20:54] [I] Max batch: explicit batch
[07/23/2023-17:20:54] [I] Memory Pools: workspace: default, dlaSRAM: default, dlaLocalDRAM: default, dlaGlobalDRAM: default
[07/23/2023-17:20:54] [I] minTiming: 1
[07/23/2023-17:20:54] [I] avgTiming: 8
[07/23/2023-17:20:54] [I] Precision: FP32
[07/23/2023-17:20:54] [I] LayerPrecisions:
[07/23/2023-17:20:54] [I] Layer Device Types:
[07/23/2023-17:20:54] [I] Calibration:
[07/23/2023-17:20:54] [I] Refit: Disabled
[07/23/2023-17:20:54] [I] Version Compatible: Disabled
[07/23/2023-17:20:54] [I] TensorRT runtime: full
[07/23/2023-17:20:54] [I] Lean DLL Path:
[07/23/2023-17:20:54] [I] Tempfile Controls: { in_memory: allow, temporary: allow }
[07/23/2023-17:20:54] [I] Exclude Lean Runtime: Disabled
[07/23/2023-17:20:54] [I] Sparsity: Disabled
[07/23/2023-17:20:54] [I] Safe mode: Disabled
[07/23/2023-17:20:54] [I] Build DLA standalone loadable: Disabled
[07/23/2023-17:20:54] [I] Allow GPU fallback for DLA: Disabled
[07/23/2023-17:20:54] [I] DirectIO mode: Disabled
[07/23/2023-17:20:54] [I] Restricted mode: Disabled
[07/23/2023-17:20:54] [I] Skip inference: Disabled
[07/23/2023-17:20:54] [I] Save engine:
[07/23/2023-17:20:54] [I] Load engine:
[07/23/2023-17:20:54] [I] Profiling verbosity: 0
[07/23/2023-17:20:54] [I] Tactic sources: Using default tactic sources
[07/23/2023-17:20:54] [I] timingCacheMode: local
[07/23/2023-17:20:54] [I] timingCacheFile:
[07/23/2023-17:20:54] [I] Heuristic: Disabled
[07/23/2023-17:20:54] [I] Preview Features: Use default preview flags.
[07/23/2023-17:20:54] [I] MaxAuxStreams: -1
[07/23/2023-17:20:54] [I] BuilderOptimizationLevel: -1
[07/23/2023-17:20:54] [I] Input(s)s format: fp32:CHW
[07/23/2023-17:20:54] [I] Output(s)s format: fp32:CHW
[07/23/2023-17:20:54] [I] Input build shapes: model
[07/23/2023-17:20:54] [I] Input calibration shapes: model
[07/23/2023-17:20:54] [I] === System Options ===
[07/23/2023-17:20:54] [I] Device: 0
[07/23/2023-17:20:54] [I] DLACore:
[07/23/2023-17:20:54] [I] Plugins:
[07/23/2023-17:20:54] [I] setPluginsToSerialize:
[07/23/2023-17:20:54] [I] dynamicPlugins:
[07/23/2023-17:20:54] [I] ignoreParsedPluginLibs: 0
[07/23/2023-17:20:54] [I]
[07/23/2023-17:20:54] [I] === Inference Options ===
[07/23/2023-17:20:54] [I] Batch: Explicit
[07/23/2023-17:20:54] [I] Input inference shapes: model
[07/23/2023-17:20:54] [I] Iterations: 1000
[07/23/2023-17:20:54] [I] Duration: 3s (+ 200ms warm up)
[07/23/2023-17:20:54] [I] Sleep time: 0ms
[07/23/2023-17:20:54] [I] Idle time: 0ms
[07/23/2023-17:20:54] [I] Inference Streams: 1
[07/23/2023-17:20:54] [I] ExposeDMA: Disabled
[07/23/2023-17:20:54] [I] Data transfers: Enabled
[07/23/2023-17:20:54] [I] Spin-wait: Disabled
[07/23/2023-17:20:54] [I] Multithreading: Disabled
[07/23/2023-17:20:54] [I] CUDA Graph: Disabled
[07/23/2023-17:20:54] [I] Separate profiling: Disabled
[07/23/2023-17:20:54] [I] Time Deserialize: Disabled
[07/23/2023-17:20:54] [I] Time Refit: Disabled
[07/23/2023-17:20:54] [I] NVTX verbosity: 0
[07/23/2023-17:20:54] [I] Persistent Cache Ratio: 0
[07/23/2023-17:20:54] [I] Inputs:
[07/23/2023-17:20:54] [I] === Reporting Options ===
[07/23/2023-17:20:54] [I] Verbose: Disabled
[07/23/2023-17:20:54] [I] Averages: 10 inferences
[07/23/2023-17:20:54] [I] Percentiles: 90,95,99
[07/23/2023-17:20:54] [I] Dump refittable layers:Disabled
[07/23/2023-17:20:54] [I] Dump output: Disabled
[07/23/2023-17:20:54] [I] Profile: Disabled
[07/23/2023-17:20:54] [I] Export timing to JSON file:
[07/23/2023-17:20:54] [I] Export output to JSON file:
[07/23/2023-17:20:54] [I] Export profile to JSON file:
[07/23/2023-17:20:54] [I]
[07/23/2023-17:20:54] [I] === Device Information ===
[07/23/2023-17:20:54] [I] Selected Device: NVIDIA GeForce RTX 4070 Ti
[07/23/2023-17:20:54] [I] Compute Capability: 8.9
[07/23/2023-17:20:54] [I] SMs: 60
[07/23/2023-17:20:54] [I] Device Global Memory: 12281 MiB
[07/23/2023-17:20:54] [I] Shared Memory per SM: 100 KiB
[07/23/2023-17:20:54] [I] Memory Bus Width: 192 bits (ECC disabled)
[07/23/2023-17:20:54] [I] Application Compute Clock Rate: 2.61 GHz
[07/23/2023-17:20:54] [I] Application Memory Clock Rate: 10.501 GHz
[07/23/2023-17:20:54] [I]
[07/23/2023-17:20:54] [I] Note: The application clock rates do not reflect the actual clock rates that the GPU is currently running at.
[07/23/2023-17:20:54] [I]
[07/23/2023-17:20:54] [I] TensorRT version: 8.6.1
[07/23/2023-17:20:54] [I] Loading standard plugins
[07/23/2023-17:20:55] [I] [TRT] [MemUsageChange] Init CUDA: CPU +336, GPU +0, now: CPU 15923, GPU 1325 (MiB)
[07/23/2023-17:20:58] [I] [TRT] [MemUsageChange] Init builder kernel library: CPU +1476, GPU +264, now: CPU 18534, GPU 1589 (MiB)
[07/23/2023-17:20:58] [W] [TRT] CUDA lazy loading is not enabled. Enabling it can significantly reduce device memory usage and speed up TensorRT initialization. See "Lazy Loading" section of CUDA documentation https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#lazy-loading
[07/23/2023-17:20:58] [I] Start parsing network model.
[07/23/2023-17:20:58] [I] [TRT] ----------------------------------------------------------------
[07/23/2023-17:20:58] [I] [TRT] Input filename:   modelzoo/onnx/resnet18.onnx
[07/23/2023-17:20:58] [I] [TRT] ONNX IR version:  0.0.6
[07/23/2023-17:20:58] [I] [TRT] Opset version:    11
[07/23/2023-17:20:58] [I] [TRT] Producer name:    pytorch
[07/23/2023-17:20:58] [I] [TRT] Producer version: 1.12.1
[07/23/2023-17:20:58] [I] [TRT] Domain:
[07/23/2023-17:20:58] [I] [TRT] Model version:    0
[07/23/2023-17:20:58] [I] [TRT] Doc string:
[07/23/2023-17:20:58] [I] [TRT] ----------------------------------------------------------------
[07/23/2023-17:20:58] [I] Finished parsing network model. Parse time: 0.0485261
[07/23/2023-17:20:58] [I] [TRT] Graph optimization time: 0.0015272 seconds.
[07/23/2023-17:20:58] [I] [TRT] Local timing cache in use. Profiling results in this builder pass will not be stored.
[07/23/2023-17:21:03] [I] [TRT] Detected 1 inputs and 1 output network tensors.
[07/23/2023-17:21:03] [I] [TRT] Total Host Persistent Memory: 88704
[07/23/2023-17:21:03] [I] [TRT] Total Device Persistent Memory: 75776
[07/23/2023-17:21:03] [I] [TRT] Total Scratch Memory: 4608
[07/23/2023-17:21:03] [I] [TRT] [MemUsageStats] Peak memory usage of TRT CPU/GPU memory allocators: CPU 25 MiB, GPU 78 MiB
[07/23/2023-17:21:03] [I] [TRT] [BlockAssignment] Started assigning block shifts. This will take 26 steps to complete.
[07/23/2023-17:21:03] [I] [TRT] [BlockAssignment] Algorithm ShiftNTopDown took 0.4837ms to assign 3 blocks to 26 nodes requiring 4816896 bytes.
[07/23/2023-17:21:03] [I] [TRT] Total Activation Memory: 4816896
[07/23/2023-17:21:03] [I] [TRT] [MemUsageChange] TensorRT-managed allocation in building engine: CPU +0, GPU +71, now: CPU 0, GPU 71 (MiB)
[07/23/2023-17:21:03] [I] Engine built in 8.88675 sec.
[07/23/2023-17:21:04] [I] [TRT] Loaded engine size: 71 MiB
[07/23/2023-17:21:04] [I] [TRT] [MemUsageChange] TensorRT-managed allocation in engine deserialization: CPU +0, GPU +70, now: CPU 0, GPU 70 (MiB)
[07/23/2023-17:21:04] [I] Engine deserialized in 0.0120581 sec.
[07/23/2023-17:21:04] [I] [TRT] [MemUsageChange] TensorRT-managed allocation in IExecutionContext creation: CPU +0, GPU +5, now: CPU 0, GPU 75 (MiB)
[07/23/2023-17:21:04] [W] [TRT] CUDA lazy loading is not enabled. Enabling it can significantly reduce device memory usage and speed up TensorRT initialization. See "Lazy Loading" section of CUDA documentation https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#lazy-loading
[07/23/2023-17:21:04] [I] Setting persistentCacheLimit to 0 bytes.
[07/23/2023-17:21:04] [I] Using random values for input input.1
[07/23/2023-17:21:04] [I] Input binding for input.1 with dimensions 1x3x224x224 is created.
[07/23/2023-17:21:04] [I] Output binding for 191 with dimensions 1x1000 is created.
[07/23/2023-17:21:04] [I] Starting inference
[07/23/2023-17:21:07] [I] Warmup completed 347 queries over 200 ms
[07/23/2023-17:21:07] [I] Timing trace has 5158 queries over 3.00157 s
[07/23/2023-17:21:07] [I]
...
[07/23/2023-17:21:07] [I] === Performance summary ===
[07/23/2023-17:21:07] [I] Throughput: 1718.43 qps
[07/23/2023-17:21:07] [I] Latency: min = 0.572998 ms, max = 1.8811 ms, mean = 0.618583 ms, median = 0.60791 ms, percentile(90%) = 0.624756 ms, percentile(95%) = 0.643555 ms, percentile(99%) = 0.890747 ms
[07/23/2023-17:21:07] [I] Enqueue Time: min = 0.0375977 ms, max = 0.809326 ms, mean = 0.0526417 ms, median = 0.0435181 ms, percentile(90%) = 0.06604 ms, percentile(95%) = 0.122803 ms, percentile(99%) = 0.163086 ms
[07/23/2023-17:21:07] [I] H2D Latency: min = 0.0341797 ms, max = 0.141846 ms, mean = 0.0422516 ms, median = 0.0418701 ms, percentile(90%) = 0.0449219 ms, percentile(95%) = 0.0470276 ms, percentile(99%) = 0.0673523 ms
[07/23/2023-17:21:07] [I] GPU Compute Time: min = 0.52124 ms, max = 1.82471 ms, mean = 0.563974 ms, median = 0.552979 ms, percentile(90%) = 0.566895 ms, percentile(95%) = 0.581635 ms, percentile(99%) = 0.8396 ms
[07/23/2023-17:21:07] [I] D2H Latency: min = 0.00537109 ms, max = 0.029541 ms, mean = 0.0123565 ms, median = 0.0134277 ms, percentile(90%) = 0.0148926 ms, percentile(95%) = 0.0153809 ms, percentile(99%) = 0.0157471 ms
[07/23/2023-17:21:07] [I] Total Host Walltime: 3.00157 s
[07/23/2023-17:21:07] [I] Total GPU Compute Time: 2.90898 s
[07/23/2023-17:21:07] [W] * GPU compute time is unstable, with coefficient of variance = 10.3215%.
[07/23/2023-17:21:07] [W]   If not already in use, locking GPU clock frequency or adding --useSpinWait may improve the stability.
[07/23/2023-17:21:07] [I] Explanations of the performance metrics are printed in the verbose logs.
[07/23/2023-17:21:07] [I]
&&&& PASSED TensorRT.trtexec [TensorRT v8601] # trtexec --onnx=modelzoo/onnx/resnet18.onnx --iterations=1000

#### WindowsML(GPUHighPerformance)
(base) PS C:\Code\mnn\MNN\build> MicrosoftMLRunner.exe -model ..\modelzoo\onnx\resnet18.onnx -iterations 1000 -perf -GPUHighPerformance
...
Results (device = GPU_High_Performance, numIterations = 1000, inputBinding = CPU, inputDataType = Tensor, deviceCreationLocation = WinML):

First Iteration Performance (load, bind, session creation, and evaluate):
  Load: 43.8238 ms
  Bind: 0.6316 ms
  Session Creation: 363.946 ms
  Evaluate: 5.0493 ms

  Working Set Memory usage (evaluate): 1.19531 MB
  Working Set Memory usage (load, bind, session creation, and evaluate): 180.953 MB
  Peak Working Set Memory Difference (load, bind, session creation, and evaluate): 182.297 MB

  Dedicated Memory usage (evaluate): 66.3906 MB
  Dedicated Memory usage (load, bind, session creation, and evaluate): 125.594 MB

  Shared Memory usage (evaluate): 3 MB
  Shared Memory usage (load, bind, session creation, and evaluate): 17.0234 MB

Average Performance excluding first iteration. Iterations 2 to 1000. (Iterations greater than 1 only bind and evaluate)
  Average Bind: 0.0834067 ms
  Average Evaluate: 0.877857 ms

  Average Working Set Memory usage (bind): 3.91016e-06 MB
  Average Working Set Memory usage (evaluate): 7.03829e-05 MB

  Average Dedicated Memory usage (bind): 0 MB
  Average Dedicated Memory usage (evaluate): 0 MB

  Average Shared Memory usage (bind): 0 MB
  Average Shared Memory usage (evaluate): 0.000398836 MB

#### WindowsML(GPU)
(base) PS C:\Code\mnn\MNN\build> MicrosoftMLRunner.exe -model ..\modelzoo\onnx\resnet18.onnx -iterations 1000 -perf -GPU 
...
Results (device = GPU, numIterations = 1000, inputBinding = CPU, inputDataType = Tensor, deviceCreationLocation = WinML):

First Iteration Performance (load, bind, session creation, and evaluate):
  Load: 26.0724 ms
  Bind: 0.2055 ms
  Session Creation: 172.703 ms
  Evaluate: 4.6258 ms

  Working Set Memory usage (evaluate): 1.19531 MB
  Working Set Memory usage (load, bind, session creation, and evaluate): 181.035 MB
  Peak Working Set Memory Difference (load, bind, session creation, and evaluate): 182.223 MB

  Dedicated Memory usage (evaluate): 66.3906 MB
  Dedicated Memory usage (load, bind, session creation, and evaluate): 125.594 MB

  Shared Memory usage (evaluate): 3 MB
  Shared Memory usage (load, bind, session creation, and evaluate): 17.0234 MB

Average Performance excluding first iteration. Iterations 2 to 1000. (Iterations greater than 1 only bind and evaluate)
  Average Bind: 0.0835366 ms
  Average Evaluate: 0.872171 ms

  Average Working Set Memory usage (bind): 0 MB
  Average Working Set Memory usage (evaluate): 3.91016e-05 MB

  Average Dedicated Memory usage (bind): 0 MB
  Average Dedicated Memory usage (evaluate): 0 MB

  Average Shared Memory usage (bind): 0 MB
  Average Shared Memory usage (evaluate): 0.000398836 MB